{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import*\n",
    "def loadSimpData():\n",
    "    datMat = matrix([[1.,  2.1],\n",
    "                     [2.,  1.1],\n",
    "                     [1.3,  1.],\n",
    "                     [1.,  1.],\n",
    "                     [2.,  1.]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat, classLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    " \n",
    "   - Numpy matrices必须是2维的,但是 numpy arrays (ndarrays) 可以是多维的（1D，2D，3D····ND）. Matrix是Array的一个小的分支，包含于Array。所以matrix 拥有array的所有特性。\n",
    "    \n",
    "   - 在numpy中matrix的主要优势是：相对简单的乘法运算符号。例如，a和b是两个matrices，那么a*b，就是矩阵积。\n",
    "   -  matrix 和 array 都可以通过objects后面加.T 得到其转置。但是 matrix objects 还可以在后面加 .H f得到共轭矩阵, 加 .I 得到逆矩阵。\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 建立一个单层的决策树函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):  # just classify the data\n",
    "    retArray = ones((shape(dataMatrix)[0],1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf   # init error sum, to +infinity\n",
    "    for i in range(n):  # loop over all dimensions\n",
    "        rangeMin = dataMatrix[:,i].min();  rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1):  # over all range in current dimension\n",
    "            for inequal in ['lt', 'gt']:   # go over less than and greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)  # call stump classify with i, j, lessThan\n",
    "                errArr = mat(ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr  #calc total error multiplied by D\n",
    "                #print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat, classLables = loadSimpData()\n",
    "D = mat(ones((5, 1))/5)\n",
    "buildStump(dataMat, classLables, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaboost实现\n",
    "\n",
    "<table border=\"1\" width=\"100%\" align=\"left\">\n",
    "  <tr>\n",
    "    <th>序号</th>\n",
    "    <th>1</th>\n",
    "    <th>2</th>\n",
    "    <th>3</th>\n",
    "    <th>4</th>\n",
    "    <th>5</th>\n",
    "    <th>6</th>\n",
    "    <th>7</th>\n",
    "    <th>8</th>\n",
    "    <th>9</th>\n",
    "    <th>10</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>x</td>\n",
    "    <td>0</td>\n",
    "    <th>1</th>\n",
    "    <th>2</th>\n",
    "    <th>3</th>\n",
    "    <th>4</th>\n",
    "    <th>5</th>\n",
    "    <th>6</th>\n",
    "    <th>7</th>\n",
    "    <th>8</th>\n",
    "    <th>9</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>y</td>\n",
    "    <td>1</td>\n",
    "     <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>-1</td>\n",
    "      <td>-1</td>\n",
    "      <td>-1</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>-1</td>\n",
    "  </tr>\n",
    "  </table>\n",
    "  \n",
    "  \n",
    "  我们以上表所示数据为例，来演示Adaboost的执行过程：\n",
    "  初始化权值分布\n",
    "  $$D_1=\\left \\{ w_{11},w_{12},w_{13},w_{14},w_{15},w_{16},w_{17},w_{18},w_{19},w_{110} \\right \\}$$\n",
    "  $$w_{1i}=0.1\\hspace{1cm}i=1,2\\cdots10$$\n",
    "  (a) 在权值为D1的训练数据上，阈值取2.5时分类器效果最好，故基本分类器为：\n",
    "  $$G_{1}=\\begin{cases}\n",
    "  1&\\text{x<2.5}\\\\\n",
    "  -1&\\text{x>2.5}\n",
    "  \\end{cases}$$\n",
    "\n",
    "(b)$G_{1}(x)$在训练集上的误差率为$e_1=P(G_{1}(x_i)\\neq y_{i})=0.3$\n",
    "\n",
    "(c)计算$G_1(x)$的系数$\\alpha_1=\\frac{1}{2}\\log\\frac{1-e_1}{e_1}=0.4236$\n",
    "\n",
    "(d)更新训练数据的权值分布：\n",
    "$$D_2=\\left \\{ w_{21},w_{22},w_{23},w_{24},w_{25},w_{26},w_{27},w_{28},w_{29},w_{210} \\right \\}$$\n",
    "$$w_{2i}=\\frac{w_{1i}}{Z_1}exp(-\\alpha_{1}y_iG_{1}(x_i))\\hspace{1cm}i=1,2\\cdots10$$\n",
    "$$D_2=\\left \\{ 0.0715,0,0715,0.0715,0.0715,0.0715,0.0715,0.1666,0.1666,0.0715 \\right \\}$$\n",
    "$$f_1(x)=0.4236G_1(x)$$\n",
    "\n",
    "分类器$sign[f_1{x}]$在训练数据集上有三个误分类点。\n",
    "\n",
    "对m=2\n",
    "\n",
    "(a) 在权值为D2的训练数据上，阈值取8.5时分类器效果最好，故基本分类器为：\n",
    "  $$G_{2}=\\begin{cases}\n",
    "  1&\\text{x<8.5}\\\\\n",
    "  -1&\\text{x>8.5}\n",
    "  \\end{cases}$$\n",
    " (b)$G_{2}(x)$在训练集上的误差率为$e_2=P(G_{2}(x_i)\\neq y_{i})=0.21413$\n",
    " \n",
    " (c)计算$G_2(x)$的系数$\\alpha_2=\\frac{1}{2}\\log\\frac{1-e_2}{e_2}=0.6496$\n",
    " \n",
    " (d)更新训练数据的权值分布：\n",
    " $$D_2=\\left \\{ 0.0455,0,0455,0.0455,0.1667,0.1667,0.1667,0.1060,0.1060,0.1060,0.0455 \\right \\}$$\n",
    " $$f_2(x)=0.4236G_1{x}+0.6496G_2(x)$$\n",
    " \n",
    " 分类器$sign[f_2{x}]$在训练数据集上有三个误分类点。\n",
    " \n",
    " 对m=3,\n",
    " \n",
    " (a) 在权值为D3的训练数据上，阈值取5.5时分类器效果最好，故基本分类器为：\n",
    "  $$G_{3}=\\begin{cases}\n",
    "  1&\\text{x<5.5}\\\\\n",
    "  -1&\\text{x>5.5}\n",
    "  \\end{cases}$$\n",
    "  \n",
    "  (b)$G_{3}(x)$在训练集上的误差率为$e_3=P(G_{3}(x_i)\\neq y_{i})=0.1820$\n",
    "  \n",
    "  (c)计算$G_3(x)$的系数$\\alpha_3=\\frac{1}{2}\\log\\frac{1-e_3}{e_3}=0.7514$\n",
    "  \n",
    "  d)更新训练数据的权值分布：\n",
    " $$D_3=\\left \\{ 0.125,0.125,0.125,0.102,0.102,0.102,0.065,0.065,0.065,0.125 \\right \\}$$\n",
    " $$f_3(x)=0.4236G_1{x}+0.6496G_2(x)+0.7514G_3(x)$$\n",
    " \n",
    " 分类器分类器$sign[f_3{x}]$在训练数据集上有零个误分类点。\n",
    " \n",
    " 于是最终分类器为：\n",
    " $$G(x)=sign[f_3(x)=sign[0.4236G_1(x)+0.6496G_2(x)+0.7514G_3(x)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)   #init D to all equal\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#build Stump\n",
    "        #print \"D:\",D.T\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#calc alpha, throw in max(error,eps) to account for error=0\n",
    "        bestStump['alpha'] = alpha  \n",
    "        weakClassArr.append(bestStump)                  #store Stump Params in Array\n",
    "        #print \"classEst: \",classEst.T\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #exponent for D calc, getting messy\n",
    "        D = multiply(D,exp(expon))                              #Calc New D for next iteration\n",
    "        D = D/D.sum()\n",
    "        #calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print \"aggClassEst: \",aggClassEst.T\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print(\"total error: \",errorRate)\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = mat(datToClass)#do stuff similar to last aggClassEst in adaBoostTrainDS\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],\\\n",
    "                                 classifierArr[i]['thresh'],\\\n",
    "                                 classifierArr[i]['ineq'])#call stump classify\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        print(aggClassEst)\n",
    "    return sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.2\n",
      "total error:  0.2\n",
      "total error:  0.0\n",
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datArr, labelArr = loadSimpData()\n",
    "classifierArr = adaBoostTrainDS(datArr, labelArr, 30)\n",
    "adaClassify([0, 0], classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
